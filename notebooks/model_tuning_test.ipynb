{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b37e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer   # 결측치값 대체.\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8c809f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32545 entries, 0 to 32544\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   code_module           32545 non-null  object \n",
      " 1   code_presentation     32545 non-null  object \n",
      " 2   id_student            32545 non-null  int64  \n",
      " 3   gender                32545 non-null  object \n",
      " 4   region                32545 non-null  object \n",
      " 5   highest_education     32545 non-null  int64  \n",
      " 6   imd_band              32545 non-null  float64\n",
      " 7   age_band              32545 non-null  int64  \n",
      " 8   num_of_prev_attempts  32545 non-null  int64  \n",
      " 9   studied_credits       32545 non-null  int64  \n",
      " 10  disability            32545 non-null  object \n",
      " 11  date_registration     32545 non-null  float64\n",
      " 12  date_unregistration   32545 non-null  float64\n",
      " 13  sum_click             32545 non-null  float64\n",
      " 14  avg_score             32545 non-null  float64\n",
      " 15  is_dropout            32545 non-null  int64  \n",
      " 16  target                32545 non-null  int64  \n",
      "dtypes: float64(5), int64(7), object(5)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "na_values_df = pd.read_csv(\"../data/final_dataset.csv\")\n",
    "na_values_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a8f9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_module</th>\n",
       "      <th>code_presentation</th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>disability</th>\n",
       "      <th>date_registration</th>\n",
       "      <th>date_unregistration</th>\n",
       "      <th>sum_click</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>is_dropout</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>11391</td>\n",
       "      <td>M</td>\n",
       "      <td>East Anglian Region</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>N</td>\n",
       "      <td>-159.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>934.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>28400</td>\n",
       "      <td>F</td>\n",
       "      <td>Scotland</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1435.0</td>\n",
       "      <td>66.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>30268</td>\n",
       "      <td>F</td>\n",
       "      <td>North Western Region</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>Y</td>\n",
       "      <td>-92.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>31604</td>\n",
       "      <td>F</td>\n",
       "      <td>South East Region</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>2158.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>2013J</td>\n",
       "      <td>32885</td>\n",
       "      <td>F</td>\n",
       "      <td>West Midlands Region</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>54.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_module code_presentation  id_student gender                region  \\\n",
       "0         AAA             2013J       11391      M   East Anglian Region   \n",
       "1         AAA             2013J       28400      F              Scotland   \n",
       "2         AAA             2013J       30268      F  North Western Region   \n",
       "3         AAA             2013J       31604      F     South East Region   \n",
       "4         AAA             2013J       32885      F  West Midlands Region   \n",
       "\n",
       "   highest_education  imd_band  age_band  num_of_prev_attempts  \\\n",
       "0                  3      10.0        60                     0   \n",
       "1                  3       3.0        45                     0   \n",
       "2                  2       4.0        45                     0   \n",
       "3                  2       6.0        45                     0   \n",
       "4                  1       6.0        30                     0   \n",
       "\n",
       "   studied_credits disability  date_registration  date_unregistration  \\\n",
       "0              240          N             -159.0               9999.0   \n",
       "1               60          N              -53.0               9999.0   \n",
       "2               60          Y              -92.0                 12.0   \n",
       "3               60          N              -52.0               9999.0   \n",
       "4               60          N             -176.0               9999.0   \n",
       "\n",
       "   sum_click  avg_score  is_dropout  target  \n",
       "0      934.0       82.0           0       0  \n",
       "1     1435.0       66.4           0       0  \n",
       "2      281.0        0.0           1       1  \n",
       "3     2158.0       76.0           0       0  \n",
       "4     1034.0       54.4           0       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_values_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded0ecc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32545, 16), (32545,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = na_values_df.drop(columns='target').values\n",
    "# X = X.astype('float32')\n",
    "y = na_values_df['target'].values\n",
    "y = y.astype(int)\n",
    "\n",
    "X.shape,  y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc707bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 488169 stored elements and shape (32545, 60)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1.0\n",
      "  (0, 8)\t1.0\n",
      "  (0, 12)\t1.0\n",
      "  (0, 13)\t1.0\n",
      "  (0, 29)\t1.0\n",
      "  (0, 40)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 44)\t1.0\n",
      "  (0, 51)\t1.0\n",
      "  (0, 53)\t1.0\n",
      "  (0, 55)\t3.905125197007625\n",
      "  (0, 56)\t-1.8185928989610989\n",
      "  (0, 57)\t0.6671221427396934\n",
      "  (0, 58)\t-0.1670317117402033\n",
      "  (0, 59)\t0.7100890620793591\n",
      "  (1, 0)\t1.0\n",
      "  (1, 8)\t1.0\n",
      "  (1, 11)\t1.0\n",
      "  (1, 19)\t1.0\n",
      "  (1, 29)\t1.0\n",
      "  (1, 33)\t1.0\n",
      "  (1, 42)\t1.0\n",
      "  (1, 44)\t1.0\n",
      "  (1, 51)\t1.0\n",
      "  (1, 53)\t1.0\n",
      "  :\t:\n",
      "  (32543, 40)\t1.0\n",
      "  (32543, 42)\t1.0\n",
      "  (32543, 44)\t1.0\n",
      "  (32543, 51)\t1.0\n",
      "  (32543, 54)\t1.0\n",
      "  (32543, 55)\t-1.211159957215567\n",
      "  (32543, 56)\t0.4144516877944941\n",
      "  (32543, 57)\t-1.487791864498921\n",
      "  (32543, 58)\t-0.5562260670917427\n",
      "  (32543, 59)\t1.0137563256706723\n",
      "  (32544, 6)\t1.0\n",
      "  (32544, 10)\t1.0\n",
      "  (32544, 11)\t1.0\n",
      "  (32544, 25)\t1.0\n",
      "  (32544, 29)\t1.0\n",
      "  (32544, 36)\t1.0\n",
      "  (32544, 42)\t1.0\n",
      "  (32544, 44)\t1.0\n",
      "  (32544, 51)\t1.0\n",
      "  (32544, 53)\t1.0\n",
      "  (32544, 55)\t-1.211159957215567\n",
      "  (32544, 56)\t0.8407601998114709\n",
      "  (32544, 57)\t0.6671221427396934\n",
      "  (32544, 58)\t-0.3548371821526305\n",
      "  (32544, 59)\t0.7374876121778235\n"
     ]
    }
   ],
   "source": [
    "fe_transformer = ColumnTransformer([\n",
    "    (\"category_ohe\", OneHotEncoder(), [0, 1, 3, 4, 5, 6, 7, 8, 10,15]),# feature의 index로 지정.   # index는 앞에 했던 배열로 적용해줘야함.\n",
    "    (\"number_scaler\", StandardScaler(), [9,11,12,13,14])    #feature Scaling은 연속형끼리 같은 방식을 사용 (standard or MinMax 중 택1)\n",
    "])\n",
    "### DataFrame이 입력일 경우 컬럼명이나 컬럼 index를 지정할 수 있다.\n",
    "### ndarray가 입력일 경우 컬럼(feature) index를 지정.\n",
    "new_merged_df = fe_transformer.fit_transform(X)\n",
    "print(new_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb96a37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32545, 60), (32545,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = new_merged_df\n",
    "X = X.astype('float32')\n",
    "X = X.toarray()\n",
    "# y = new_merged_df['target'].values\n",
    "y = y.astype(int)\n",
    "X.shape,  y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec1745e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " >>> Tuning Decision Tree...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "- Complete:4.59325초\n",
      "\n",
      " >>> Tuning Random Forest...\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "- Complete:2.64032초\n",
      "\n",
      " >>> Tuning KNN...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "- Complete:6.93645초\n",
      "\n",
      " >>> Tuning SVM...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "- Complete:23.29396초\n",
      "\n",
      " >>> Tuning XGBoost...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "- Complete:4.71000초\n",
      "\n",
      " >>> Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "- Complete:4.54953초\n",
      "\n",
      " >>> Tuning SGDClassifier...\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "- Complete:0.77907초\n",
      "\n",
      " >>> Tuning AdaBoost...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "- Complete:7.24347초\n",
      "\n",
      " >>> Tuning CatBoost...\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "- Complete:39.73229초\n",
      "\n",
      " >>> Tuning Naive Bayes...\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "- Complete:0.21924초\n",
      "\n",
      " >>> Tuning LightGBM...\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[LightGBM] [Info] Number of positive: 13707, number of negative: 12329\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 922\n",
      "[LightGBM] [Info] Number of data points in the train set: 26036, number of used features: 58\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.526463 -> initscore=0.105952\n",
      "[LightGBM] [Info] Start training from score 0.105952\n",
      "- Complete:16.59630초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimzi\\miniconda3\\envs\\pj2\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✔] 전체 모델과 지표가 저장되었습니다: ../model/all_models.pkl\n",
      "\n",
      "=== Final Comparison ===\n",
      "              Model                                                                      Best Params  Train Accuracy (CV)  Test Accuracy\n",
      "           CatBoost         {'depth': 5, 'iterations': 500, 'l2_leaf_reg': 5, 'learning_rate': 0.03}             0.900983       0.899370\n",
      "            XGBoost                    {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 1000}             0.899485       0.898448\n",
      "           LightGBM                    {'learning_rate': 0.1, 'n_estimators': 100, 'num_leaves': 50}             0.898525       0.896451\n",
      "      Random Forest                    {'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 100}             0.884660       0.887079\n",
      "                SVM                                     {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}             0.882932       0.886311\n",
      "Logistic Regression                                    {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}             0.881741       0.886311\n",
      "           AdaBoost                                      {'learning_rate': 1.0, 'n_estimators': 100}             0.880934       0.882778\n",
      "      SGDClassifier    {'alpha': 0.01, 'eta0': 0.1, 'learning_rate': 'adaptive', 'loss': 'log_loss'}             0.878169       0.882163\n",
      "                KNN                                         {'n_neighbors': 5, 'weights': 'uniform'}             0.846021       0.852512\n",
      "      Decision Tree {'max_depth': 2, 'max_features': 10, 'max_leaf_nodes': 3, 'min_samples_leaf': 2}             0.849939       0.848517\n",
      "        Naive Bayes                                                         {'var_smoothing': 1e-07}             0.798241       0.798587\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimzi\\miniconda3\\envs\\pj2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m     44\u001b[39m param_grids = {\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDecision Tree\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     46\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_depth\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[32m    101\u001b[39m }\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# 함수 실행\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m results_df, best_models = \u001b[43mauto_model_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SKN13_Documnet\\SKN13_2nd_project\\SKN13-2nd-3TEAM\\util\\model_tuning.py:105\u001b[39m, in \u001b[36mauto_model_tuning\u001b[39m\u001b[34m(base_models, param_grids, X, y, test_size, random_state, cv, n_jobs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(results_df.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# 5. 시각화\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[43mplot_model_performance_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# 6. 성능 리포트 출력\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name, estimator \u001b[38;5;129;01min\u001b[39;00m best_estimators.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\SKN13_Documnet\\SKN13_2nd_project\\SKN13-2nd-3TEAM\\util\\visualizer.py:22\u001b[39m, in \u001b[36mplot_model_performance_comparison\u001b[39m\u001b[34m(results_df, figsize)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_model_performance_comparison\u001b[39m(results_df, figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m)):\n\u001b[32m     21\u001b[39m     fig, ax = plt.subplots(figsize=figsize)\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     bars = ax.barh(results_df[\u001b[33m'\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m'\u001b[39m], \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, color=\u001b[33m'\u001b[39m\u001b[33mskyblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     23\u001b[39m     ax.set_xlabel(\u001b[33m'\u001b[39m\u001b[33mTest Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m     ax.set_title(\u001b[33m'\u001b[39m\u001b[33mModel Performance Comparison\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimzi\\miniconda3\\envs\\pj2\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimzi\\miniconda3\\envs\\pj2\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0UAAAH/CAYAAACYSXaPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHl9JREFUeJzt3XtsV/X9+PF3AQHNBHUMEFZl6rxNBQVBQGJc0CYaHH8sY2iEEC9zOqMQJ+AFvOO8hWRWiajTZHGgRJwRUqdMYhwsRNBEM8AoKsRYLnNQRAWFzy/v8/21o9g6ir1QXo9Hcgaf03Pa81ne1D57znmfslKpVEoAAABBdWjrAwAAAGhLoggAAAhNFAEAAKGJIgAAIDRRBAAAhCaKAACA0EQRAAAQmigCAABCE0UAAEBooggAAAityVH0+uuvp1GjRqU+ffqksrKy9MILL/zPfRYvXpzOOOOM1KVLl3Tcccelp556al+PFwAAoG2jaNu2bal///6psrJyr7b/8MMP04UXXpjOPffc9Pbbb6frr78+XX755enll1/el+MFAABoVmWlUqm0zzuXlaX58+en0aNHN7rN5MmT04IFC9K7775bt+7Xv/512rx5c6qqqtrXLw0AANAsOqUWtnTp0jRy5Mh66yoqKoozRo3Zvn17sdTatWtX+uyzz9IPf/jDIsQAAICYSqVS2rp1a3E7T4cOHdpHFFVXV6devXrVW5df19TUpC+//DIdfPDB39pnxowZ6fbbb2/pQwMAANqpdevWpR//+MftI4r2xdSpU9OkSZPqXm/ZsiUdddRRxRvv1q1bmx4bAADQdvLJlfLy8nTooYc22+ds8Sjq3bt3Wr9+fb11+XWOm4bOEmV5lrq87CnvI4oAAICyZrytpsWfUzR06NC0aNGieuteeeWVYj0AAEBba3IUff7558XU2nmpnXI7/33t2rV1l76NGzeubvurrroqrVmzJt14441p1apV6ZFHHknPPvtsmjhxYnO+DwAAgNaJojfffDOdfvrpxZLle3/y36dNm1a8/vTTT+sCKfvJT35STMmdzw7l5xs9+OCD6fHHHy9moAMAAGjXzylqzZupunfvXky44J4iAACIq6YF2qDF7ykCAADYn4kiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoe1TFFVWVqZ+/fqlrl27piFDhqRly5Z95/YzZ85MJ5xwQjr44INTeXl5mjhxYvrqq6/29ZgBAADaLormzp2bJk2alKZPn55WrFiR+vfvnyoqKtKGDRsa3P6ZZ55JU6ZMKbZfuXJleuKJJ4rPcdNNNzXH8QMAALRuFD300EPpiiuuSBMmTEgnn3xymjVrVjrkkEPSk08+2eD2S5YsScOHD08XX3xxcXbp/PPPT2PHjv2fZ5cAAAD2uyjasWNHWr58eRo5cuR/P0GHDsXrpUuXNrjPsGHDin1qI2jNmjVp4cKF6YILLvi+xw4AAPC9dWrKxps2bUo7d+5MvXr1qrc+v161alWD++QzRHm/s88+O5VKpfTNN9+kq6666jsvn9u+fXux1KqpqWnKYQIAAOw/s88tXrw43XPPPemRRx4p7kF6/vnn04IFC9Kdd97Z6D4zZsxI3bt3r1vy5AwAAAAtoayUT9804fK5fP/QvHnz0ujRo+vWjx8/Pm3evDn99a9//dY+I0aMSGeddVa6//7769b9+c9/TldeeWX6/PPPi8vv9uZMUQ6jLVu2pG7dujX1PQIAAAeImpqa4sRJc7ZBk84Ude7cOQ0cODAtWrSobt2uXbuK10OHDm1wny+++OJb4dOxY8fiz8Z6rEuXLsUb3H0BAABo83uKsjwddz4zNGjQoDR48ODiGUTbtm0rZqPLxo0bl/r27VtcApeNGjWqmLHu9NNPL55p9P7776dbb721WF8bRwAAAO0misaMGZM2btyYpk2blqqrq9OAAQNSVVVV3eQLa9eurXdm6JZbbkllZWXFn5988kn60Y9+VATR3Xff3bzvBAAAoKXvKTqQrhsEAADanza/pwgAAOBAI4oAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQRBEAABCaKAIAAEITRQAAQGiiCAAACE0UAQAAoYkiAAAgNFEEAACEJooAAIDQ9imKKisrU79+/VLXrl3TkCFD0rJly75z+82bN6drrrkmHXnkkalLly7p+OOPTwsXLtzXYwYAAGg2nZq6w9y5c9OkSZPSrFmziiCaOXNmqqioSKtXr049e/b81vY7duxI5513XvGxefPmpb59+6aPP/44HXbYYc31HgAAAPZZWalUKjVlhxxCZ555Znr44YeL17t27Url5eXp2muvTVOmTPnW9jme7r///rRq1ap00EEH7dNB1tTUpO7du6ctW7akbt267dPnAAAA2r+aFmiDJl0+l8/6LF++PI0cOfK/n6BDh+L10qVLG9znxRdfTEOHDi0un+vVq1c65ZRT0j333JN27tzZ6NfZvn178WZ3XwAAAFpCk6Jo06ZNRczkuNldfl1dXd3gPmvWrCkum8v75fuIbr311vTggw+mu+66q9GvM2PGjKL+apd8JgoAAKBdzj6XL6/L9xM99thjaeDAgWnMmDHp5ptvLi6ra8zUqVOL02G1y7p161r6MAEAgKCaNNFCjx49UseOHdP69evrrc+ve/fu3eA+eca5fC9R3q/WSSedVJxZypfjde7c+Vv75Bnq8gIAALBfnSnKAZPP9ixatKjemaD8Ot831JDhw4en999/v9iu1nvvvVfEUkNBBAAAsF9fPpen4549e3Z6+umn08qVK9Nvf/vbtG3btjRhwoTi4+PGjSsuf6uVP/7ZZ5+l6667roihBQsWFBMt5IkXAAAA2t1zivI9QRs3bkzTpk0rLoEbMGBAqqqqqpt8Ye3atcWMdLXyJAkvv/xymjhxYjrttNOK5xTlQJo8eXLzvhMAAIDWeE5RW/CcIgAAYL94ThEAAMCBRhQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAIbZ+iqLKyMvXr1y917do1DRkyJC1btmyv9pszZ04qKytLo0eP3pcvCwAA0PZRNHfu3DRp0qQ0ffr0tGLFitS/f/9UUVGRNmzY8J37ffTRR+mGG25II0aM+D7HCwAA0LZR9NBDD6UrrrgiTZgwIZ188slp1qxZ6ZBDDklPPvlko/vs3LkzXXLJJen2229PxxxzzPc9ZgAAgLaJoh07dqTly5enkSNH/vcTdOhQvF66dGmj+91xxx2pZ8+e6bLLLturr7N9+/ZUU1NTbwEAAGjzKNq0aVNx1qdXr1711ufX1dXVDe7zxhtvpCeeeCLNnj17r7/OjBkzUvfu3euW8vLyphwmAADA/jH73NatW9Oll15aBFGPHj32er+pU6emLVu21C3r1q1rycMEAAAC69SUjXPYdOzYMa1fv77e+vy6d+/e39r+gw8+KCZYGDVqVN26Xbt2/d8X7tQprV69Oh177LHf2q9Lly7FAgAAsF+dKercuXMaOHBgWrRoUb3Iya+HDh36re1PPPHE9M4776S33367brnooovSueeeW/zdZXEAAEC7OlOU5em4x48fnwYNGpQGDx6cZs6cmbZt21bMRpeNGzcu9e3bt7gvKD/H6JRTTqm3/2GHHVb8ued6AACAdhFFY8aMSRs3bkzTpk0rJlcYMGBAqqqqqpt8Ye3atcWMdAAAAO1BWalUKqX9XJ6SO89Clydd6NatW1sfDgAAcAC1gVM6AABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAIbZ+iqLKyMvXr1y917do1DRkyJC1btqzRbWfPnp1GjBiRDj/88GIZOXLkd24PAACwX0fR3Llz06RJk9L06dPTihUrUv/+/VNFRUXasGFDg9svXrw4jR07Nr322mtp6dKlqby8PJ1//vnpk08+aY7jBwAA+F7KSqVSqSk75DNDZ555Znr44YeL17t27SpC59prr01Tpkz5n/vv3LmzOGOU9x83btxefc2amprUvXv3tGXLltStW7emHC4AAHAAqWmBNmjSmaIdO3ak5cuXF5fA1X2CDh2K1/ks0N744osv0tdff52OOOKIRrfZvn178WZ3XwAAAFpCk6Jo06ZNxZmeXr161VufX1dXV+/V55g8eXLq06dPvbDa04wZM4r6q13ymSgAAIB2P/vcvffem+bMmZPmz59fTNLQmKlTpxanw2qXdevWteZhAgAAgXRqysY9evRIHTt2TOvXr6+3Pr/u3bv3d+77wAMPFFH06quvptNOO+07t+3SpUuxAAAA7Fdnijp37pwGDhyYFi1aVLcuT7SQXw8dOrTR/e6777505513pqqqqjRo0KDvd8QAAABtdaYoy9Nxjx8/voibwYMHp5kzZ6Zt27alCRMmFB/PM8r17du3uC8o+8Mf/pCmTZuWnnnmmeLZRrX3Hv3gBz8oFgAAgHYVRWPGjEkbN24sQicHzoABA4ozQLWTL6xdu7aYka7Wo48+Wsxa98tf/rLe58nPObrtttua4z0AAAC03nOK2oLnFAEAAPvFc4oAAAAONKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaKIIAAAITRQBAAChiSIAACA0UQQAAIQmigAAgNBEEQAAEJooAgAAQhNFAABAaPsURZWVlalfv36pa9euaciQIWnZsmXfuf1zzz2XTjzxxGL7U089NS1cuHBfjxcAAKBto2ju3Llp0qRJafr06WnFihWpf//+qaKiIm3YsKHB7ZcsWZLGjh2bLrvssvTWW2+l0aNHF8u7777bHMcPAADwvZSVSqVSU3bIZ4bOPPPM9PDDDxevd+3alcrLy9O1116bpkyZ8q3tx4wZk7Zt25ZeeumlunVnnXVWGjBgQJo1a9Zefc2amprUvXv3tGXLltStW7emHC4AAHAAqWmBNujUlI137NiRli9fnqZOnVq3rkOHDmnkyJFp6dKlDe6T1+czS7vLZ5ZeeOGFRr/O9u3bi6VWfsO1/wcAAABx1fz/JmjiuZ3mi6JNmzalnTt3pl69etVbn1+vWrWqwX2qq6sb3D6vb8yMGTPS7bff/q31+YwUAADAv//97+KMUatHUWvJZ6J2P7u0efPmdPTRR6e1a9c22xuHxn7zkON73bp1LtWkRRlrtBZjjdZirNFa8lVkRx11VDriiCOa7XM2KYp69OiROnbsmNavX19vfX7du3fvBvfJ65uyfdalS5di2VMOIv/IaA15nBlrtAZjjdZirNFajDVaS76Np9k+V1M27ty5cxo4cGBatGhR3bo80UJ+PXTo0Ab3yet33z575ZVXGt0eAACgNTX58rl8Wdv48ePToEGD0uDBg9PMmTOL2eUmTJhQfHzcuHGpb9++xX1B2XXXXZfOOeec9OCDD6YLL7wwzZkzJ7355pvpsccea/53AwAA0NJRlKfY3rhxY5o2bVoxWUKeWruqqqpuMoV838/up7KGDRuWnnnmmXTLLbekm266Kf30pz8tZp475ZRT9vpr5kvp8nORGrqkDpqTsUZrMdZoLcYarcVYoz2PtSY/pwgAAOBA0nx3JwEAALRDoggAAAhNFAEAAKGJIgAAILT9JooqKytTv379UteuXdOQIUPSsmXLvnP75557Lp144onF9qeeempauHBhqx0r7VtTxtrs2bPTiBEj0uGHH14sI0eO/J9jE/b1+1qt/OiCsrKyNHr06BY/RmKOtc2bN6drrrkmHXnkkcXsTccff7z/jtIiYy0/uuWEE05IBx98cCovL08TJ05MX331VasdL+3P66+/nkaNGpX69OlT/Lcwz1r9vyxevDidccYZxfez4447Lj311FPtM4rmzp1bPP8oT623YsWK1L9//1RRUZE2bNjQ4PZLlixJY8eOTZdddll66623ih8c8vLuu++2+rHTvjR1rOV/ZHmsvfbaa2np0qXFN/Tzzz8/ffLJJ61+7BzYY63WRx99lG644YYixqElxtqOHTvSeeedV4y1efPmpdWrVxe/AMrPGITmHGv5kSxTpkwptl+5cmV64oknis+RH9ECjcnPP81jKwf43vjwww+LZ6Gee+656e23307XX399uvzyy9PLL7+cmqS0Hxg8eHDpmmuuqXu9c+fOUp8+fUozZsxocPtf/epXpQsvvLDeuiFDhpR+85vftPix0r41dazt6ZtvvikdeuihpaeffroFj5KoYy2Pr2HDhpUef/zx0vjx40u/+MUvWuloiTTWHn300dIxxxxT2rFjRyseJRHHWt725z//eb11kyZNKg0fPrzFj5UDQ0qpNH/+/O/c5sYbbyz97Gc/q7duzJgxpYqKiiZ9rTY/U5R/Y7V8+fLisqRa+eGv+XX+zXxD8vrdt8/ybyoa2x72dazt6Ysvvkhff/11OuKII1rwSIk61u64447Us2fP4iw4tNRYe/HFF9PQoUOLy+fyg9fzw9TvueeetHPnzlY8ciKMtWHDhhX71F5it2bNmuIyzQsuuKDVjpsD39Jm6oJOqY1t2rSp+EacvzHvLr9etWpVg/tUV1c3uH1eD8051vY0efLk4hrXPf/xwfcda2+88UZxaUk+9Q8tOdbyD6Z///vf0yWXXFL8gPr++++nq6++uviFT77MCZprrF188cXFfmeffXa+Mil988036aqrrnL5HM2qsS6oqalJX375ZXE/295o8zNF0F7ce++9xQ3w8+fPL24wheaydevWdOmllxb3dfTo0aOtD4cD3K5du4ozko899lgaOHBgGjNmTLr55pvTrFmz2vrQOMDk+3LzWchHHnmkuAfp+eefTwsWLEh33nlnWx8a7H9nivIPAB07dkzr16+vtz6/7t27d4P75PVN2R72dazVeuCBB4ooevXVV9Npp53WwkdKtLH2wQcfFDe959l2dv/BNevUqVNxI/yxxx7bCkdOhO9reca5gw46qNiv1kknnVT8tjVfItW5c+cWP25ijLVbb721+IVPvuk9y7MF55vor7zyyiLE8+V38H011gXdunXb67NEWZuPxvzNN/+matGiRfV+GMiv8zXPDcnrd98+e+WVVxrdHvZ1rGX33Xdf8VutqqqqNGjQoFY6WiKNtfx4gXfeeae4dK52ueiii+pm0smzHkJzfV8bPnx4cclcbXhn7733XhFLgojmHGv5Ptw9w6c2xv/vHnr4/pqtC0r7gTlz5pS6dOlSeuqpp0r/+te/SldeeWXpsMMOK1VXVxcfv/TSS0tTpkyp2/4f//hHqVOnTqUHHnigtHLlytL06dNLBx10UOmdd95pw3dBe9DUsXbvvfeWOnfuXJo3b17p008/rVu2bt3ahu+CA3Gs7cnsc7TUWFu7dm0xi+bvfve70urVq0svvfRSqWfPnqW77rqrDd8FB+JYyz+f5bH2l7/8pbRmzZrS3/72t9Kxxx5bzCIMjck/Y7311lvFklPloYceKv7+8ccfFx/PYyyPtVp5bB1yyCGl3//+90UXVFZWljp27FiqqqoqNcV+EUXZH//4x9JRRx1V/ACap3z85z//Wfexc845p/gBYXfPPvts6fjjjy+2z9PwLViwoA2OmvaoKWPt6KOPLv5B7rnkb/TQ3N/XdieKaMmxtmTJkuJRFvkH3Dw99913311MCQ/NOda+/vrr0m233VaEUNeuXUvl5eWlq6++uvSf//ynjY6e9uC1115r8Gev2rGV/8xjbc99BgwYUIzL/D3tT3/6U5O/bln+n2Y4cwUAANAutfk9RQAAAG1JFAEAAKGJIgAAIDRRBAAAhCaKAACA0EQRAAAQmigCAABCE0UAAEBooggAAAhNFAEAAKGJIgAAIDRRBAAApMj+Hw1SB7JF2kG7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "# 상위 폴더를 Python 경로에 추가\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from util.model_tuning import auto_model_tuning\n",
    "from util.model_io import save_model, load_model, save_models, load_models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "X = new_merged_df\n",
    "X = X.astype('float32')\n",
    "X = X.toarray()\n",
    "\n",
    "y = y.astype(int)\n",
    "\n",
    "\n",
    "base_models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=5000, random_state=42),\n",
    "    \"SGDClassifier\": SGDClassifier(random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "    # \"MLPClassifier\": MLPClassifier(max_iter=1000, early_stopping=True, random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Decision Tree\": {\n",
    "        \"max_depth\":range(1, 5),\n",
    "        \"max_leaf_nodes\": [3, 5, 10],\n",
    "        \"min_samples_leaf\": [2, 5, 10],\n",
    "        \"max_features\": [1, 5, 10]},\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100], #200, 300],\n",
    "        'max_depth':[10],#, 20, 30],\n",
    "        \"min_samples_leaf\": [2]#, 5, 10],\n",
    "        },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors':[3,5],\n",
    "        'weights': ['uniform', 'distance']},\n",
    "    \"SVM\": {\n",
    "        'C': [0.1], #[0.001,   #, 0.1, 1, 10],\n",
    "        'gamma': [0.1], #[0.01, 0.1, 1, 10],\n",
    "        'kernel': ['linear']},\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [1000],\n",
    "        'learning_rate' : [0.01],\n",
    "        'max_depth': [5]},\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.1],  # 규제 강도\n",
    "        'penalty': [ 'l2'],  # 규제 유형\n",
    "        'solver': ['saga']},\n",
    "    \"SGDClassifier\": {\n",
    "        'loss': ['log_loss', 'hinge'],  # log_loss=로지스틱, hinge=SVM\n",
    "        'alpha': [ 0.01],  # 규제 계수\n",
    "        'learning_rate': ['adaptive'],\n",
    "        'eta0': [0.1]},\n",
    "    \"AdaBoost\": {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.5, 1.0]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [500], #(500, 5001, 500),\n",
    "        'depth': [4, 5], #range(4,11),\n",
    "        'learning_rate': [0.03], # [0.01, 0.03, 0.05, 0.1, 0.3],\n",
    "        'l2_leaf_reg' : [1,3,5] #range(1, 11)\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        # GaussianNB has no hyperparameters commonly tuned, but for structure:\n",
    "        'var_smoothing': [1e-9, 1e-8, 1e-7]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [100],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'num_leaves': [31, 50]\n",
    "    }\n",
    "    # \"MLPClassifier\": {\n",
    "    #     'hidden_layer_sizes': [(50,), (100,), (50, 30)],\n",
    "    #     'activation': ['relu', 'tanh'],\n",
    "    #     'alpha': [0.0001, 0.001],  # L2 규제 강도\n",
    "    #     'learning_rate_init': [0.001, 0.01],\n",
    "    #     'batch_size': [32, 64]\n",
    "    # }\n",
    "}\n",
    "\n",
    "# 함수 실행\n",
    "results_df, best_models = auto_model_tuning(base_models, param_grids, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed82b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3025675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# 1. 모델 및 전처리 로드\n",
    "with open(\"../model/all_models.pkl\", \"rb\") as f:\n",
    "    model_bundle = pickle.load(f)\n",
    "\n",
    "# 가장 성능이 높은 모델 선택\n",
    "best_model_name = max(model_bundle, key=lambda name: model_bundle[name][\"metrics\"][\"test_accuracy\"])\n",
    "best_model = model_bundle[best_model_name][\"model\"]\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "\n",
    "# 2. 전처리기 다시 정의 (학습 때 사용한 구조와 동일하게)\n",
    "fe_transformer = ColumnTransformer([\n",
    "    (\"category_ohe\", OneHotEncoder(handle_unknown='ignore'), [0, 1, 3, 4, 5, 6, 7, 8, 10, 15]),\n",
    "    (\"number_scaler\", StandardScaler(), [9,11,12,13,14])\n",
    "])\n",
    "\n",
    "# 3. 기존 데이터 불러오기 (유사도 비교용)\n",
    "base_df = pd.read_csv(\"../data/final_dataset.csv\")\n",
    "X_base = base_df.drop(columns=\"target\")\n",
    "\n",
    "# 4. 새로운 입력 데이터 예시 (범주형만 입력)\n",
    "new_input = pd.DataFrame([{\n",
    "    0: \"A\", 1: \"B\", 3: \"C\", 4: \"D\", 5: \"E\", 6: \"F\", 7: \"G\", 8: \"H\", 10: \"I\", 15: \"J\"\n",
    "}], dtype=object)\n",
    "\n",
    "# 5. 기존 데이터와 범주형만 동일한 기준으로 변환\n",
    "cat_columns = [0, 1, 3, 4, 5, 6, 7, 8, 10, 15]\n",
    "num_columns = [9, 11, 12, 13, 14]\n",
    "\n",
    "X_base_cat = X_base[cat_columns]\n",
    "new_cat_input = new_input[cat_columns]\n",
    "\n",
    "# 원핫 인코딩만 따로 적용해서 비교용 데이터 생성\n",
    "cat_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_base_cat_encoded = cat_encoder.fit_transform(X_base_cat).toarray()\n",
    "new_cat_encoded = cat_encoder.transform(new_cat_input).toarray()\n",
    "\n",
    "# 6. 유사한 기존 데이터 1개 선택\n",
    "similarities = cosine_similarity(new_cat_encoded, X_base_cat_encoded)\n",
    "most_similar_index = np.argmax(similarities)\n",
    "\n",
    "# 7. 해당 인덱스의 수치형 컬럼을 사용해 입력 데이터 보완\n",
    "new_complete_input = new_input.copy()\n",
    "for col in num_columns:\n",
    "    new_complete_input[col] = X_base.iloc[most_similar_index, col]\n",
    "\n",
    "# 수치형까지 포함된 최종 입력 데이터를 원래 순서로 정렬\n",
    "new_complete_input = new_complete_input.reindex(columns=X_base.columns)\n",
    "\n",
    "# 8. 전처리 후 예측\n",
    "fe_transformer.fit(X_base.values)  # 원본 데이터로 전처기 학습\n",
    "X_transformed = fe_transformer.transform(new_complete_input.values).toarray()\n",
    "\n",
    "# 예측\n",
    "prediction = best_model.predict(X_transformed)\n",
    "print(\"✅ 예측 결과:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
